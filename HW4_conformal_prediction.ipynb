{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HW4 \u2013 Conformal Prediction for Image Classification (Naive, APS, RAPS)\n",
        "\n",
        "This notebook implements conformal prediction methods for image classification following **Angelopoulos et al., ICLR 2021**. It uses a pretrained **ResNet-152** (configurable) on ImageNet-1k and evaluates on the ImageNet validation set (if available) and the ImageNetV2 matched-frequency split. We compare three prediction-set methods:\n",
        "\n",
        "- **Naive cumulative probability thresholding** (no conformal calibration)\n",
        "- **APS (Adaptive Prediction Sets)**\n",
        "- **RAPS (Regularized Adaptive Prediction Sets)**\n",
        "\n",
        "Experiments mirror the paper:\n",
        "1. Coverage vs set size on ImageNet-Val\n",
        "2. Coverage vs set size on ImageNetV2 (distribution shift)\n",
        "3. Histograms of set sizes for varying $\\lambda$\n",
        "4. Adaptiveness of RAPS vs image difficulty\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets, models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "try:\n",
        "    from huggingface_hub import hf_hub_download\n",
        "    HF_AVAILABLE = True\n",
        "except ImportError:\n",
        "    HF_AVAILABLE = False\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "\n",
        "def set_seed(seed: int = 0):\n",
        "    \"\"\"Set random seeds for reproducibility.\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "IMAGENET_ROOT = \"/path/to/imagenet\"  # user: set this if you have ImageNet locally\n",
        "IMAGENETV2_ROOT = \"./data/imagenetv2-matched-frequency\"\n",
        "RESULTS_DIR = \"./results\"\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "NUM_CLASSES = 1000\n",
        "BATCH_SIZE = 64\n",
        "NUM_WORKERS = 4\n",
        "\n",
        "ALPHAS = [0.05, 0.10]  # target miscoverage\n",
        "\n",
        "IMAGENET_N_CAL = 20000\n",
        "IMAGENET_N_EVAL = 20000\n",
        "IMAGENETV2_N_CAL = 5000\n",
        "IMAGENETV2_N_EVAL = 5000\n",
        "\n",
        "DEFAULT_KREG = 5\n",
        "DEFAULT_LAMBDA = 0.2\n",
        "RAPS_LAMBDAS_FOR_EXP3 = [0.0, 0.001, 0.01, 0.1, 1.0]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "imagenet_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "\n",
        "def load_imagenet_val(root: str):\n",
        "    \"\"\"Load ImageNet validation set if available locally.\"\"\"\n",
        "    if not os.path.isdir(root):\n",
        "        print(\"ImageNet root not found, skipping ImageNet experiments.\")\n",
        "        return None\n",
        "    ds = datasets.ImageNet(root=root, split=\"val\", transform=imagenet_transform)\n",
        "    print(\"Loaded ImageNet-Val with\", len(ds), \"images.\")\n",
        "    return ds\n",
        "\n",
        "\n",
        "def ensure_imagenetv2_matched_frequency(root: str):\n",
        "    \"\"\"Ensure ImageNetV2 matched-frequency files are present, downloading if necessary.\"\"\"\n",
        "    os.makedirs(root, exist_ok=True)\n",
        "    if any(os.scandir(root)):\n",
        "        print(\"ImageNetV2 directory not empty; assuming data is present.\")\n",
        "        return root\n",
        "\n",
        "    if not HF_AVAILABLE:\n",
        "        raise RuntimeError(\"huggingface_hub not installed; install it or manually extract the tar.\")\n",
        "\n",
        "    print(\"Downloading ImageNetV2 matched-frequency from Hugging Face...\")\n",
        "    tar_path = hf_hub_download(\n",
        "        repo_id=\"vaishaal/ImageNetV2\",\n",
        "        filename=\"imagenetv2-matched-frequency.tar.gz\"\n",
        "    )\n",
        "\n",
        "    import tarfile\n",
        "    with tarfile.open(tar_path, \"r:gz\") as tar:\n",
        "        tar.extractall(path=root)\n",
        "\n",
        "    print(\"Extracted ImageNetV2 under\", root)\n",
        "    return root\n",
        "\n",
        "\n",
        "def load_imagenetv2(root: str):\n",
        "    \"\"\"Load ImageNetV2 matched-frequency split via ImageFolder.\"\"\"\n",
        "    ensure_imagenetv2_matched_frequency(root)\n",
        "    entries = [e for e in os.scandir(root) if e.is_dir()]\n",
        "    if len(entries) == 1:\n",
        "        data_root = entries[0].path\n",
        "    else:\n",
        "        data_root = root\n",
        "\n",
        "    ds = datasets.ImageFolder(root=data_root, transform=imagenet_transform)\n",
        "    print(\"Loaded ImageNetV2 matched-frequency with\", len(ds), \"images.\")\n",
        "    return ds\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "imagenet_val = load_imagenet_val(IMAGENET_ROOT)\n",
        "imagenetv2 = load_imagenetv2(IMAGENETV2_ROOT)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def split_for_calibration_and_eval(\n",
        "    dataset,\n",
        "    n_cal: int,\n",
        "    n_eval: int,\n",
        "    seed: int = 0\n",
        ") -> Tuple[Subset, Subset]:\n",
        "    indices = np.arange(len(dataset))\n",
        "    rng = np.random.default_rng(seed)\n",
        "    rng.shuffle(indices)\n",
        "\n",
        "    n_total = min(len(indices), n_cal + n_eval)\n",
        "    indices = indices[:n_total]\n",
        "\n",
        "    cal_indices = indices[: min(n_cal, len(indices))]\n",
        "    eval_indices = indices[min(n_cal, len(indices)): min(n_cal + n_eval, len(indices))]\n",
        "\n",
        "    cal_set = Subset(dataset, cal_indices)\n",
        "    eval_set = Subset(dataset, eval_indices)\n",
        "    return cal_set, eval_set\n",
        "\n",
        "\n",
        "def make_loader(dataset, batch_size: int = BATCH_SIZE, shuffle: bool = False):\n",
        "    return DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def load_pretrained_model(model_name: str = \"resnet152\") -> nn.Module:\n",
        "    \"\"\"Load a pretrained ImageNet classifier.\"\"\"\n",
        "    if model_name == \"resnet152\":\n",
        "        model = models.resnet152(weights=models.ResNet152_Weights.IMAGENET1K_V2)\n",
        "    elif model_name == \"resnet50\":\n",
        "        model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model_name: {model_name}\")\n",
        "    model.eval()\n",
        "    model.to(DEVICE)\n",
        "    return model\n",
        "\n",
        "\n",
        "class TemperatureScaler(nn.Module):\n",
        "    \"\"\"Simple temperature scaling for logits.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.log_temperature = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    @property\n",
        "    def temperature(self):\n",
        "        return torch.exp(self.log_temperature)\n",
        "\n",
        "    def forward(self, logits: torch.Tensor) -> torch.Tensor:\n",
        "        return logits / self.temperature\n",
        "\n",
        "\n",
        "def fit_temperature(model: nn.Module, loader: DataLoader, max_iters: int = 100) -> TemperatureScaler:\n",
        "    \"\"\"Fit temperature scaling using NLL loss on provided loader.\"\"\"\n",
        "    model.eval()\n",
        "    scaler = TemperatureScaler().to(DEVICE)\n",
        "    nll = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.LBFGS([scaler.log_temperature], lr=0.1)\n",
        "\n",
        "    logits_list = []\n",
        "    labels_list = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(loader, desc=\"Collecting logits for temperature scaling\"):\n",
        "            images = images.to(DEVICE)\n",
        "            logits = model(images)\n",
        "            logits_list.append(logits.cpu())\n",
        "            labels_list.append(labels)\n",
        "\n",
        "    logits_all = torch.cat(logits_list, dim=0).to(DEVICE)\n",
        "    labels_all = torch.cat(labels_list, dim=0).to(DEVICE)\n",
        "\n",
        "    def eval_loss():\n",
        "        optimizer.zero_grad()\n",
        "        loss = nll(scaler(logits_all), labels_all)\n",
        "        loss.backward()\n",
        "        return loss\n",
        "\n",
        "    for _ in range(max_iters):\n",
        "        optimizer.step(eval_loss)\n",
        "\n",
        "    print(f\"Fitted temperature: {scaler.temperature.item():.4f}\")\n",
        "    scaler.eval()\n",
        "    return scaler\n",
        "\n",
        "\n",
        "def get_logits_and_labels(model: nn.Module, loader: DataLoader, temperature_scaler: TemperatureScaler = None):\n",
        "    \"\"\"Compute logits and labels for a dataset loader.\"\"\"\n",
        "    model.eval()\n",
        "    logits_list = []\n",
        "    labels_list = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(loader, desc=\"Getting logits\"):\n",
        "            images = images.to(DEVICE)\n",
        "            logits = model(images)\n",
        "            if temperature_scaler is not None:\n",
        "                logits = temperature_scaler(logits)\n",
        "            logits_list.append(logits.cpu())\n",
        "            labels_list.append(labels)\n",
        "\n",
        "    logits_all = torch.cat(logits_list, dim=0)\n",
        "    labels_all = torch.cat(labels_list, dim=0)\n",
        "    return logits_all, labels_all\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def softmax_logits_to_probs(logits: torch.Tensor) -> torch.Tensor:\n",
        "    return torch.nn.functional.softmax(logits, dim=1)\n",
        "\n",
        "\n",
        "def sorted_probs_and_indices(probs: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    sorted_probs, sorted_indices = torch.sort(probs, dim=1, descending=True)\n",
        "    return sorted_probs, sorted_indices\n",
        "\n",
        "\n",
        "def true_label_ranks(sorted_indices: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
        "    N, K = sorted_indices.shape\n",
        "    labels_expanded = labels.view(N, 1).expand(-1, K)\n",
        "    matches = (sorted_indices == labels_expanded)\n",
        "    ranks = matches.float().argmax(dim=1)\n",
        "    return ranks\n",
        "\n",
        "\n",
        "def cumulative_probs(sorted_probs: torch.Tensor) -> torch.Tensor:\n",
        "    return torch.cumsum(sorted_probs, dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def naive_set_sizes(sorted_probs: torch.Tensor, alphas: List[float]) -> Dict[float, torch.Tensor]:\n",
        "    cumsums = cumulative_probs(sorted_probs)\n",
        "    N, K = sorted_probs.shape\n",
        "    sizes_by_alpha = {}\n",
        "\n",
        "    for alpha in alphas:\n",
        "        threshold = 1.0 - alpha\n",
        "        mask = (cumsums >= threshold)\n",
        "        first_true = mask.float().argmax(dim=1)\n",
        "        no_true = ~mask.any(dim=1)\n",
        "        first_true[no_true] = K - 1\n",
        "        sizes_by_alpha[alpha] = first_true + 1\n",
        "    return sizes_by_alpha\n",
        "\n",
        "\n",
        "def naive_prediction_sets(sorted_indices: torch.Tensor, set_sizes: torch.Tensor) -> List[torch.Tensor]:\n",
        "    N, K = sorted_indices.shape\n",
        "    sets = []\n",
        "    for i in range(N):\n",
        "        L = int(set_sizes[i].item())\n",
        "        sets.append(sorted_indices[i, :L])\n",
        "    return sets\n",
        "\n",
        "\n",
        "def raps_calibrate(sorted_probs: torch.Tensor,\n",
        "                   sorted_indices: torch.Tensor,\n",
        "                   labels: torch.Tensor,\n",
        "                   alpha: float,\n",
        "                   lambda_: float,\n",
        "                   k_reg: int,\n",
        "                   randomized: bool = True,\n",
        "                   rng: np.random.Generator = None) -> float:\n",
        "    if rng is None:\n",
        "        rng = np.random.default_rng(0)\n",
        "\n",
        "    N, K = sorted_probs.shape\n",
        "    ranks = true_label_ranks(sorted_indices, labels)\n",
        "    cumsums = cumulative_probs(sorted_probs)\n",
        "\n",
        "    S_true = cumsums[torch.arange(N), ranks]\n",
        "    ranks_1based = ranks + 1\n",
        "    penalty = lambda_ * torch.clamp(ranks_1based - k_reg, min=0).float()\n",
        "\n",
        "    E = S_true + penalty\n",
        "\n",
        "    if randomized:\n",
        "        U = torch.from_numpy(rng.uniform(size=N)).float()\n",
        "        true_probs = sorted_probs[torch.arange(N), ranks]\n",
        "        E = E - U * true_probs\n",
        "\n",
        "    E_np = E.numpy()\n",
        "    n = len(E_np)\n",
        "    q_index = int(np.ceil((1.0 - alpha) * (n + 1))) - 1\n",
        "    q_index = np.clip(q_index, 0, n - 1)\n",
        "    tau_hat = float(np.partition(E_np, q_index)[q_index])\n",
        "    return tau_hat\n",
        "\n",
        "\n",
        "def raps_set_sizes(sorted_probs: torch.Tensor,\n",
        "                   alpha: float,\n",
        "                   lambda_: float,\n",
        "                   k_reg: int,\n",
        "                   tau_hat: float) -> torch.Tensor:\n",
        "    N, K = sorted_probs.shape\n",
        "    cumsums = cumulative_probs(sorted_probs)\n",
        "\n",
        "    ranks_1based = torch.arange(1, K + 1)\n",
        "    penalties = lambda_ * torch.clamp(ranks_1based - k_reg, min=0).float()\n",
        "    penalties = penalties.view(1, K).expand(N, -1)\n",
        "\n",
        "    E_all = cumsums + penalties\n",
        "\n",
        "    mask = (E_all > tau_hat)\n",
        "    all_false = ~mask.any(dim=1)\n",
        "    first_exceed = mask.float().argmax(dim=1)\n",
        "    first_exceed[all_false] = K\n",
        "\n",
        "    sizes = first_exceed\n",
        "    sizes[all_false] = K\n",
        "    sizes = torch.clamp(sizes, min=1)\n",
        "    return sizes\n",
        "\n",
        "\n",
        "def aps_calibrate_and_sizes(sorted_probs_cal, sorted_indices_cal, labels_cal,\n",
        "                            sorted_probs_eval, alpha, k_reg=0):\n",
        "    tau_hat = raps_calibrate(\n",
        "        sorted_probs_cal, sorted_indices_cal, labels_cal,\n",
        "        alpha=alpha, lambda_=0.0, k_reg=k_reg\n",
        "    )\n",
        "    sizes = raps_set_sizes(\n",
        "        sorted_probs_eval, alpha=alpha,\n",
        "        lambda_=0.0, k_reg=k_reg, tau_hat=tau_hat\n",
        "    )\n",
        "    return tau_hat, sizes\n",
        "\n",
        "\n",
        "def raps_calibrate_and_sizes(sorted_probs_cal, sorted_indices_cal, labels_cal,\n",
        "                             sorted_probs_eval, alpha,\n",
        "                             lambda_=DEFAULT_LAMBDA, k_reg=DEFAULT_KREG):\n",
        "    tau_hat = raps_calibrate(\n",
        "        sorted_probs_cal, sorted_indices_cal, labels_cal,\n",
        "        alpha=alpha, lambda_=lambda_, k_reg=k_reg\n",
        "    )\n",
        "    sizes = raps_set_sizes(\n",
        "        sorted_probs_eval, alpha=alpha,\n",
        "        lambda_=lambda_, k_reg=k_reg, tau_hat=tau_hat\n",
        "    )\n",
        "    return tau_hat, sizes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def compute_scores_for_dataset(model: nn.Module,\n",
        "                               dataset,\n",
        "                               n_cal: int,\n",
        "                               n_eval: int,\n",
        "                               seed: int = 0,\n",
        "                               temperature_scaler: TemperatureScaler = None):\n",
        "    cal_set, eval_set = split_for_calibration_and_eval(dataset, n_cal, n_eval, seed=seed)\n",
        "    cal_loader = make_loader(cal_set, shuffle=False)\n",
        "    eval_loader = make_loader(eval_set, shuffle=False)\n",
        "\n",
        "    logits_cal, labels_cal = get_logits_and_labels(model, cal_loader, temperature_scaler)\n",
        "    logits_eval, labels_eval = get_logits_and_labels(model, eval_loader, temperature_scaler)\n",
        "\n",
        "    probs_cal = torch.softmax(logits_cal, dim=1)\n",
        "    probs_eval = torch.softmax(logits_eval, dim=1)\n",
        "\n",
        "    s_cal, I_cal = sorted_probs_and_indices(probs_cal)\n",
        "    s_eval, I_eval = sorted_probs_and_indices(probs_eval)\n",
        "\n",
        "    return {\n",
        "        \"cal\": {\"logits\": logits_cal, \"labels\": labels_cal, \"probs\": probs_cal, \"sorted_probs\": s_cal, \"sorted_indices\": I_cal},\n",
        "        \"eval\": {\"logits\": logits_eval, \"labels\": labels_eval, \"probs\": probs_eval, \"sorted_probs\": s_eval, \"sorted_indices\": I_eval},\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def coverage_from_set_sizes_and_labels(\n",
        "    sorted_indices: torch.Tensor,\n",
        "    set_sizes: torch.Tensor,\n",
        "    labels: torch.Tensor\n",
        ") -> float:\n",
        "    N, K = sorted_indices.shape\n",
        "    correct = 0\n",
        "    for i in range(N):\n",
        "        L = int(set_sizes[i].item())\n",
        "        preds = sorted_indices[i, :L]\n",
        "        if int(labels[i].item()) in preds.tolist():\n",
        "            correct += 1\n",
        "    return correct / float(N)\n",
        "\n",
        "\n",
        "def average_set_size(set_sizes: torch.Tensor) -> float:\n",
        "    return float(set_sizes.float().mean().item())\n",
        "\n",
        "\n",
        "def topk_accuracies_from_probs(probs: torch.Tensor,\n",
        "                               labels: torch.Tensor,\n",
        "                               ks=(1, 5)) -> Dict[int, float]:\n",
        "    _, topk_indices = probs.topk(max(ks), dim=1)\n",
        "    results = {}\n",
        "    for k in ks:\n",
        "        correct = (topk_indices[:, :k] == labels.view(-1, 1)).any(dim=1).float().mean().item()\n",
        "        results[k] = correct\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 1 \u2013 Coverage vs set size on ImageNet-Val\n",
        "\n",
        "Run Naive, APS, and RAPS on ImageNet validation set (if available)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if imagenet_val is None:\n",
        "    print(\"ImageNet not available; skipping Experiment 1.\")\n",
        "else:\n",
        "    model = load_pretrained_model(\"resnet152\")\n",
        "\n",
        "    scores_imagenet = compute_scores_for_dataset(\n",
        "        model,\n",
        "        dataset=imagenet_val,\n",
        "        n_cal=IMAGENET_N_CAL,\n",
        "        n_eval=IMAGENET_N_EVAL,\n",
        "        seed=0,\n",
        "        temperature_scaler=None,\n",
        "    )\n",
        "\n",
        "    s_cal = scores_imagenet[\"cal\"][\"sorted_probs\"]\n",
        "    I_cal = scores_imagenet[\"cal\"][\"sorted_indices\"]\n",
        "    labels_cal = scores_imagenet[\"cal\"][\"labels\"]\n",
        "\n",
        "    s_eval = scores_imagenet[\"eval\"][\"sorted_probs\"]\n",
        "    I_eval = scores_imagenet[\"eval\"][\"sorted_indices\"]\n",
        "    labels_eval = scores_imagenet[\"eval\"][\"labels\"]\n",
        "\n",
        "    topk = topk_accuracies_from_probs(scores_imagenet[\"eval\"][\"probs\"], labels_eval)\n",
        "\n",
        "    rows = []\n",
        "    for alpha in ALPHAS:\n",
        "        sizes_naive = naive_set_sizes(s_eval, [alpha])[alpha]\n",
        "        cov_naive = coverage_from_set_sizes_and_labels(I_eval, sizes_naive, labels_eval)\n",
        "        rows.append({\"alpha\": alpha, \"method\": \"Naive\", \"coverage\": cov_naive, \"avg_set_size\": average_set_size(sizes_naive)})\n",
        "\n",
        "        tau_aps, sizes_aps = aps_calibrate_and_sizes(s_cal, I_cal, labels_cal, s_eval, alpha, k_reg=0)\n",
        "        cov_aps = coverage_from_set_sizes_and_labels(I_eval, sizes_aps, labels_eval)\n",
        "        rows.append({\"alpha\": alpha, \"method\": \"APS\", \"coverage\": cov_aps, \"avg_set_size\": average_set_size(sizes_aps)})\n",
        "\n",
        "        tau_raps, sizes_raps = raps_calibrate_and_sizes(s_cal, I_cal, labels_cal, s_eval, alpha, lambda_=DEFAULT_LAMBDA, k_reg=DEFAULT_KREG)\n",
        "        cov_raps = coverage_from_set_sizes_and_labels(I_eval, sizes_raps, labels_eval)\n",
        "        rows.append({\"alpha\": alpha, \"method\": \"RAPS\", \"coverage\": cov_raps, \"avg_set_size\": average_set_size(sizes_raps)})\n",
        "\n",
        "    df_exp1 = pd.DataFrame(rows)\n",
        "    df_exp1[\"top1\"] = topk[1]\n",
        "    df_exp1[\"top5\"] = topk[5]\n",
        "    display(df_exp1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 2 \u2013 Coverage vs set size on ImageNetV2\n",
        "\n",
        "Repeat on the ImageNetV2 matched-frequency split to assess robustness under distribution shift."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if imagenetv2 is None:\n",
        "    print(\"ImageNetV2 not available; skipping Experiment 2.\")\n",
        "else:\n",
        "    model = load_pretrained_model(\"resnet152\")\n",
        "\n",
        "    scores_imagenetv2 = compute_scores_for_dataset(\n",
        "        model,\n",
        "        dataset=imagenetv2,\n",
        "        n_cal=IMAGENETV2_N_CAL,\n",
        "        n_eval=IMAGENETV2_N_EVAL,\n",
        "        seed=1,\n",
        "        temperature_scaler=None,\n",
        "    )\n",
        "\n",
        "    s_cal = scores_imagenetv2[\"cal\"][\"sorted_probs\"]\n",
        "    I_cal = scores_imagenetv2[\"cal\"][\"sorted_indices\"]\n",
        "    labels_cal = scores_imagenetv2[\"cal\"][\"labels\"]\n",
        "\n",
        "    s_eval = scores_imagenetv2[\"eval\"][\"sorted_probs\"]\n",
        "    I_eval = scores_imagenetv2[\"eval\"][\"sorted_indices\"]\n",
        "    labels_eval = scores_imagenetv2[\"eval\"][\"labels\"]\n",
        "\n",
        "    topk = topk_accuracies_from_probs(scores_imagenetv2[\"eval\"][\"probs\"], labels_eval)\n",
        "\n",
        "    rows = []\n",
        "    for alpha in ALPHAS:\n",
        "        sizes_naive = naive_set_sizes(s_eval, [alpha])[alpha]\n",
        "        cov_naive = coverage_from_set_sizes_and_labels(I_eval, sizes_naive, labels_eval)\n",
        "        rows.append({\"alpha\": alpha, \"method\": \"Naive\", \"coverage\": cov_naive, \"avg_set_size\": average_set_size(sizes_naive)})\n",
        "\n",
        "        tau_aps, sizes_aps = aps_calibrate_and_sizes(s_cal, I_cal, labels_cal, s_eval, alpha, k_reg=0)\n",
        "        cov_aps = coverage_from_set_sizes_and_labels(I_eval, sizes_aps, labels_eval)\n",
        "        rows.append({\"alpha\": alpha, \"method\": \"APS\", \"coverage\": cov_aps, \"avg_set_size\": average_set_size(sizes_aps)})\n",
        "\n",
        "        tau_raps, sizes_raps = raps_calibrate_and_sizes(s_cal, I_cal, labels_cal, s_eval, alpha, lambda_=DEFAULT_LAMBDA, k_reg=DEFAULT_KREG)\n",
        "        cov_raps = coverage_from_set_sizes_and_labels(I_eval, sizes_raps, labels_eval)\n",
        "        rows.append({\"alpha\": alpha, \"method\": \"RAPS\", \"coverage\": cov_raps, \"avg_set_size\": average_set_size(sizes_raps)})\n",
        "\n",
        "    df_exp2 = pd.DataFrame(rows)\n",
        "    df_exp2[\"top1\"] = topk[1]\n",
        "    df_exp2[\"top5\"] = topk[5]\n",
        "    display(df_exp2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 3 \u2013 Histograms of set sizes for different $\\lambda$\n",
        "\n",
        "Visualize how RAPS set sizes vary with the regularization parameter $\\lambda$ for a fixed $\u0007lpha$ (default 0.1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "alpha_hist = 0.1\n",
        "\n",
        "def plot_histograms_for_dataset(s_cal, I_cal, labels_cal, s_eval, I_eval, labels_eval, dataset_name: str):\n",
        "    sizes_naive = naive_set_sizes(s_eval, [alpha_hist])[alpha_hist]\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.hist(sizes_naive.numpy(), bins=range(1, 50), alpha=0.7, label=\"Naive\")\n",
        "    plt.title(f\"Experiment 3 \u2013 Naive set sizes (alpha={alpha_hist}, {dataset_name})\")\n",
        "    plt.xlabel(\"Set size\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    tau_aps, sizes_aps = aps_calibrate_and_sizes(s_cal, I_cal, labels_cal, s_eval, alpha_hist, k_reg=0)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.hist(sizes_aps.numpy(), bins=range(1, 50), alpha=0.7, label=\"APS\")\n",
        "    plt.title(f\"Experiment 3 \u2013 APS set sizes (alpha={alpha_hist}, {dataset_name})\")\n",
        "    plt.xlabel(\"Set size\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    for lambda_ in RAPS_LAMBDAS_FOR_EXP3:\n",
        "        tau_raps, sizes_raps = raps_calibrate_and_sizes(\n",
        "            s_cal, I_cal, labels_cal, s_eval, alpha_hist, lambda_=lambda_, k_reg=DEFAULT_KREG\n",
        "        )\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        plt.hist(sizes_raps.numpy(), bins=range(1, 50), alpha=0.7, label=f\"RAPS lambda={lambda_}\")\n",
        "        plt.title(f\"Experiment 3 \u2013 RAPS set sizes (alpha={alpha_hist}, lambda={lambda_}, {dataset_name})\")\n",
        "        plt.xlabel(\"Set size\")\n",
        "        plt.ylabel(\"Count\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "if imagenet_val is not None:\n",
        "    scores = scores_imagenet if 'scores_imagenet' in globals() else None\n",
        "    if scores is None:\n",
        "        model = load_pretrained_model(\"resnet152\")\n",
        "        scores = compute_scores_for_dataset(model, imagenet_val, IMAGENET_N_CAL, IMAGENET_N_EVAL)\n",
        "    plot_histograms_for_dataset(\n",
        "        scores[\"cal\"][\"sorted_probs\"], scores[\"cal\"][\"sorted_indices\"], scores[\"cal\"][\"labels\"],\n",
        "        scores[\"eval\"][\"sorted_probs\"], scores[\"eval\"][\"sorted_indices\"], scores[\"eval\"][\"labels\"],\n",
        "        dataset_name=\"ImageNet-Val\"\n",
        "    )\n",
        "elif imagenetv2 is not None:\n",
        "    scores = scores_imagenetv2 if 'scores_imagenetv2' in globals() else None\n",
        "    if scores is None:\n",
        "        model = load_pretrained_model(\"resnet152\")\n",
        "        scores = compute_scores_for_dataset(model, imagenetv2, IMAGENETV2_N_CAL, IMAGENETV2_N_EVAL)\n",
        "    plot_histograms_for_dataset(\n",
        "        scores[\"cal\"][\"sorted_probs\"], scores[\"cal\"][\"sorted_indices\"], scores[\"cal\"][\"labels\"],\n",
        "        scores[\"eval\"][\"sorted_probs\"], scores[\"eval\"][\"sorted_indices\"], scores[\"eval\"][\"labels\"],\n",
        "        dataset_name=\"ImageNetV2\"\n",
        "    )\n",
        "else:\n",
        "    print(\"No datasets available for Experiment 3.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 4 \u2013 Adaptiveness of RAPS vs difficulty\n",
        "\n",
        "Analyze how RAPS set sizes change across difficulty bins defined by true-class probabilities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "alpha_adapt = 0.1\n",
        "lambda_adapt = DEFAULT_LAMBDA\n",
        "\n",
        "\n",
        "def analyze_adaptiveness(s_cal, I_cal, labels_cal, s_eval, I_eval, labels_eval, dataset_name: str):\n",
        "    tau_raps, sizes_raps = raps_calibrate_and_sizes(\n",
        "        s_cal, I_cal, labels_cal, s_eval, alpha_adapt, lambda_=lambda_adapt, k_reg=DEFAULT_KREG\n",
        "    )\n",
        "\n",
        "    true_ranks = true_label_ranks(I_eval, labels_eval)\n",
        "    true_probs = s_eval[torch.arange(len(s_eval)), true_ranks]\n",
        "\n",
        "    quantiles = torch.quantile(true_probs, torch.tensor([0.25, 0.5, 0.75]))\n",
        "    bins = [true_probs < quantiles[0],\n",
        "            (true_probs >= quantiles[0]) & (true_probs < quantiles[1]),\n",
        "            (true_probs >= quantiles[1]) & (true_probs < quantiles[2]),\n",
        "            true_probs >= quantiles[2]]\n",
        "\n",
        "    avg_sizes = []\n",
        "    coverages = []\n",
        "    for i, mask in enumerate(bins):\n",
        "        idx = mask.nonzero(as_tuple=False).squeeze(1)\n",
        "        bin_sizes = sizes_raps[idx]\n",
        "        bin_labels = labels_eval[idx]\n",
        "        bin_indices = I_eval[idx]\n",
        "        avg_sizes.append(average_set_size(bin_sizes))\n",
        "        coverages.append(coverage_from_set_sizes_and_labels(bin_indices, bin_sizes, bin_labels))\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.bar(range(1, 5), avg_sizes)\n",
        "    plt.xlabel(\"Difficulty bin (1=hardest, 4=easiest)\")\n",
        "    plt.ylabel(\"Average set size\")\n",
        "    plt.title(f\"Experiment 4 \u2013 Average set size by difficulty ({dataset_name})\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.bar(range(1, 5), coverages)\n",
        "    plt.xlabel(\"Difficulty bin (1=hardest, 4=easiest)\")\n",
        "    plt.ylabel(\"Coverage\")\n",
        "    plt.title(f\"Experiment 4 \u2013 Coverage by difficulty ({dataset_name})\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if imagenet_val is not None:\n",
        "    scores = scores_imagenet if 'scores_imagenet' in globals() else None\n",
        "    if scores is None:\n",
        "        model = load_pretrained_model(\"resnet152\")\n",
        "        scores = compute_scores_for_dataset(model, imagenet_val, IMAGENET_N_CAL, IMAGENET_N_EVAL)\n",
        "    analyze_adaptiveness(\n",
        "        scores[\"cal\"][\"sorted_probs\"], scores[\"cal\"][\"sorted_indices\"], scores[\"cal\"][\"labels\"],\n",
        "        scores[\"eval\"][\"sorted_probs\"], scores[\"eval\"][\"sorted_indices\"], scores[\"eval\"][\"labels\"],\n",
        "        dataset_name=\"ImageNet-Val\"\n",
        "    )\n",
        "elif imagenetv2 is not None:\n",
        "    scores = scores_imagenetv2 if 'scores_imagenetv2' in globals() else None\n",
        "    if scores is None:\n",
        "        model = load_pretrained_model(\"resnet152\")\n",
        "        scores = compute_scores_for_dataset(model, imagenetv2, IMAGENETV2_N_CAL, IMAGENETV2_N_EVAL)\n",
        "    analyze_adaptiveness(\n",
        "        scores[\"cal\"][\"sorted_probs\"], scores[\"cal\"][\"sorted_indices\"], scores[\"cal\"][\"labels\"],\n",
        "        scores[\"eval\"][\"sorted_probs\"], scores[\"eval\"][\"sorted_indices\"], scores[\"eval\"][\"labels\"],\n",
        "        dataset_name=\"ImageNetV2\"\n",
        "    )\n",
        "else:\n",
        "    print(\"No datasets available for Experiment 4.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary & Notes for Written Report\n",
        "\n",
        "Fill in these bullets after running the experiments:\n",
        "\n",
        "- **Implementation details:** frameworks, model variants, dataset availability, any approximations.\n",
        "- **Experiment 1 (ImageNet-Val):** coverage vs average set size for Naive/APS/RAPS.\n",
        "- **Experiment 2 (ImageNetV2):** coverage vs average set size under distribution shift.\n",
        "- **Experiment 3:** qualitative effect of $\\lambda$ on set size histograms.\n",
        "- **Experiment 4:** adaptiveness of RAPS across difficulty bins.\n",
        "- **Critique & extensions:** strengths, limitations, and potential improvements.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}