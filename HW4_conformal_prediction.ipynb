{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HW4 â€“ Conformal Prediction for Image Classification (Naive, APS, RAPS)\n",
        "\n",
        "This notebook implements conformal prediction methods for image classification following **Angelopoulos et al., ICLR 2021**. It uses a pretrained **ResNet-152** (configurable) on ImageNet-1k and evaluates on the ImageNet validation set (if available) and the ImageNetV2 matched-frequency split. We compare three prediction-set methods:\n",
        "\n",
        "- **Naive cumulative probability thresholding** (no conformal calibration)\n",
        "- **APS (Adaptive Prediction Sets)**\n",
        "- **RAPS (Regularized Adaptive Prediction Sets)**\n",
        "\n",
        "Experiments mirror the paper:\n",
        "1. Coverage vs set size on ImageNet-Val\n",
        "2. Coverage vs set size on ImageNetV2 (distribution shift)\n",
        "3. Histograms of set sizes for varying $\\lambda$\n",
        "4. Adaptiveness of RAPS vs image difficulty\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets, models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "try:\n",
        "    from huggingface_hub import hf_hub_download\n",
        "    HF_AVAILABLE = True\n",
        "except ImportError:\n",
        "    HF_AVAILABLE = False\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "\n",
        "def set_seed(seed: int = 0):\n",
        "    \"\"\"Set random seeds for reproducibility.\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d3f012cf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "RECOVERY & DIAGNOSTICS\n",
            "============================================================\n",
            "\n",
            "ðŸ“ Saved Score Files:\n",
            "  âœ“ scores_imagenet_cal20000_eval20000_seed0.pt (763.2 MB)\n",
            "  âœ“ scores_imagenetv2_cal5000_eval5000_seed1.pt (190.8 MB)\n",
            "\n",
            "âœ“ No checkpoint files (all computations complete)\n",
            "\n",
            "ðŸ§¹ Cleaning up memory...\n",
            "  âœ“ Python garbage collection completed\n",
            "\n",
            "ðŸ’¾ Variables in memory:\n",
            "  âœ“ scores_imagenet (ImageNet scores)\n",
            "\n",
            "============================================================\n",
            "RECOVERY INSTRUCTIONS:\n",
            "============================================================\n",
            "1. If scores are saved, just re-run the experiment cell\n",
            "2. It will automatically load from cache\n",
            "3. If you see checkpoint files, computation will resume\n",
            "4. To reduce memory usage, reduce BATCH_SIZE or NUM_WORKERS in Cell 3\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Recovery & Diagnostics Cell\n",
        "# Run this cell after a kernel crash to check saved progress and free memory\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import gc\n",
        "\n",
        "# Define RESULTS_DIR if not already defined\n",
        "if 'RESULTS_DIR' not in globals():\n",
        "    RESULTS_DIR = \"./results\"\n",
        "    os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"RECOVERY & DIAGNOSTICS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Check saved scores\n",
        "print(\"\\nðŸ“ Saved Score Files:\")\n",
        "score_files = glob.glob(os.path.join(RESULTS_DIR, \"scores_*.pt\"))\n",
        "checkpoint_files = glob.glob(os.path.join(RESULTS_DIR, \"*_checkpoint.pt\"))\n",
        "if score_files:\n",
        "    for f in sorted(score_files):\n",
        "        size_mb = os.path.getsize(f) / (1024 * 1024)\n",
        "        print(f\"  âœ“ {os.path.basename(f)} ({size_mb:.1f} MB)\")\n",
        "else:\n",
        "    print(\"  No saved scores found\")\n",
        "\n",
        "# Check checkpoint files (incomplete computations)\n",
        "if checkpoint_files:\n",
        "    print(\"\\nâ¸ï¸  Checkpoint Files (incomplete computations):\")\n",
        "    for f in sorted(checkpoint_files):\n",
        "        size_mb = os.path.getsize(f) / (1024 * 1024)\n",
        "        print(f\"  âš  {os.path.basename(f)} ({size_mb:.1f} MB)\")\n",
        "    print(\"  â†’ These will be used to resume computation\")\n",
        "else:\n",
        "    print(\"\\nâœ“ No checkpoint files (all computations complete)\")\n",
        "\n",
        "# Memory cleanup\n",
        "print(\"\\nðŸ§¹ Cleaning up memory...\")\n",
        "gc.collect()\n",
        "try:\n",
        "    import torch\n",
        "    if hasattr(torch, 'cuda') and torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"  âœ“ CUDA cache cleared\")\n",
        "except:\n",
        "    pass  # torch not available or not imported yet\n",
        "print(\"  âœ“ Python garbage collection completed\")\n",
        "\n",
        "# Check available variables\n",
        "print(\"\\nðŸ’¾ Variables in memory:\")\n",
        "try:\n",
        "    if 'scores_imagenet' in globals():\n",
        "        print(\"  âœ“ scores_imagenet (ImageNet scores)\")\n",
        "except:\n",
        "    pass\n",
        "try:\n",
        "    if 'scores_imagenetv2' in globals():\n",
        "        print(\"  âœ“ scores_imagenetv2 (ImageNetV2 scores)\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"RECOVERY INSTRUCTIONS:\")\n",
        "print(\"=\" * 60)\n",
        "print(\"1. If scores are saved, just re-run the experiment cell\")\n",
        "print(\"2. It will automatically load from cache\")\n",
        "print(\"3. If you see checkpoint files, computation will resume\")\n",
        "print(\"4. To reduce memory usage, reduce BATCH_SIZE or NUM_WORKERS in Cell 3\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45a4da7a",
      "metadata": {},
      "source": [
        "## Checkpointing & Progress Saving\n",
        "\n",
        "**This notebook includes automatic checkpointing to prevent data loss if the kernel shuts down.**\n",
        "\n",
        "### Features:\n",
        "- **Automatic caching**: Computed scores are automatically saved to `./results/` directory\n",
        "- **Incremental checkpoints**: Progress is saved every 10 batches during logit computation\n",
        "- **Resume capability**: If interrupted, the computation will automatically resume from the last checkpoint\n",
        "\n",
        "### Tips to prevent kernel shutdowns:\n",
        "1. **Reduce batch size** if you're running out of memory (set `BATCH_SIZE` lower)\n",
        "2. **Reduce number of workers** if you have memory issues (set `NUM_WORKERS = 0` or `1`)\n",
        "3. **Process datasets separately**: Run ImageNet and ImageNetV2 experiments separately\n",
        "4. **Monitor memory usage**: Close other applications to free up RAM\n",
        "5. **Use smaller evaluation sets**: Reduce `IMAGENET_N_EVAL` or `IMAGENETV2_N_EVAL` for faster testing\n",
        "\n",
        "### Manual checkpoint management:\n",
        "- Cached scores are saved as `.pt` files in `./results/`\n",
        "- To force recomputation, delete the cache files or set `use_cache=False`\n",
        "- Checkpoint files (`.pt` files with `_checkpoint` in name) are automatically cleaned up after successful completion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMAGENET_ROOT = r\"C:\\Users\\ducta\\Downloads\"  # user: set this to parent directory containing devkit and val folder\n",
        "IMAGENETV2_ROOT = r\"\\Users\\ducta\\Downloads\\imagenetv2-matched-frequency\"\n",
        "RESULTS_DIR = \"./results\"\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "NUM_CLASSES = 1000\n",
        "BATCH_SIZE = 32  # Reduced from 64 to prevent crashes. Increase to 64 if you have enough RAM\n",
        "NUM_WORKERS = 0  # Set to 0 to disable multiprocessing (saves memory). Increase to 2-4 if you have enough RAM\n",
        "\n",
        "ALPHAS = [0.05, 0.10]  # target miscoverage\n",
        "\n",
        "IMAGENET_N_CAL = 20000\n",
        "IMAGENET_N_EVAL = 20000\n",
        "IMAGENETV2_N_CAL = 5000\n",
        "IMAGENETV2_N_EVAL = 5000\n",
        "\n",
        "DEFAULT_KREG = 5\n",
        "DEFAULT_LAMBDA = 0.2\n",
        "RAPS_LAMBDAS_FOR_EXP3 = [0.0, 0.001, 0.01, 0.1, 1.0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "imagenet_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "\n",
        "def load_imagenet_val(root: str):\n",
        "    \"\"\"Load ImageNet validation set if available locally.\"\"\"\n",
        "    if not os.path.isdir(root):\n",
        "        print(\"ImageNet root not found, skipping ImageNet experiments.\")\n",
        "        return None\n",
        "    \n",
        "    # Check if root points directly to val images folder, use parent if so\n",
        "    val_folder_names = [\"val\", \"ILSVRC2012_img_val\"]\n",
        "    if os.path.basename(root) in val_folder_names:\n",
        "        parent_root = os.path.dirname(root)\n",
        "        if os.path.isdir(parent_root):\n",
        "            print(f\"Detected val folder, using parent directory: {parent_root}\")\n",
        "            root = parent_root\n",
        "    \n",
        "    # Check for standard ImageNet structure\n",
        "    devkit_file = os.path.join(root, \"ILSVRC2012_devkit_t12.tar.gz\")\n",
        "    devkit_folder = os.path.join(root, \"ILSVRC2012_devkit_t12\")\n",
        "    val_tar = os.path.join(root, \"ILSVRC2012_img_val.tar\")\n",
        "    val_folder = os.path.join(root, \"val\")\n",
        "    \n",
        "    # Check if devkit exists (either as tar.gz or extracted folder)\n",
        "    has_devkit = os.path.exists(devkit_file) or os.path.isdir(devkit_folder)\n",
        "    \n",
        "    # If we have extracted val folder but no devkit, try to find devkit in parent\n",
        "    if os.path.isdir(val_folder) and not has_devkit:\n",
        "        parent_dir = os.path.dirname(root)\n",
        "        parent_devkit_file = os.path.join(parent_dir, \"ILSVRC2012_devkit_t12.tar.gz\")\n",
        "        parent_devkit_folder = os.path.join(parent_dir, \"ILSVRC2012_devkit_t12\")\n",
        "        if os.path.exists(parent_devkit_file) or os.path.isdir(parent_devkit_folder):\n",
        "            root = parent_dir\n",
        "            print(f\"Found devkit in parent, using: {root}\")\n",
        "    \n",
        "    try:\n",
        "        ds = datasets.ImageNet(root=root, split=\"val\", transform=imagenet_transform)\n",
        "        print(\"Loaded ImageNet-Val with\", len(ds), \"images.\")\n",
        "        return ds\n",
        "    except RuntimeError as e:\n",
        "        error_msg = str(e).lower()\n",
        "        if \"devkit\" in error_msg or \"archive\" in error_msg or \"tar\" in error_msg:\n",
        "            print(f\"Cannot load ImageNet: {e}\")\n",
        "            print(\"\\nTo fix this, ensure your IMAGENET_ROOT points to a directory containing:\")\n",
        "            print(\"  1. ILSVRC2012_devkit_t12.tar.gz (devkit archive)\")\n",
        "            print(\"  2. ILSVRC2012_img_val.tar (validation images archive) OR a 'val' folder\")\n",
        "            print(f\"\\nCurrent root: {root}\")\n",
        "            print(\"If your images are extracted, the root should be the parent directory.\")\n",
        "            return None\n",
        "        else:\n",
        "            raise\n",
        "\n",
        "\n",
        "def ensure_imagenetv2_matched_frequency(root: str):\n",
        "    \"\"\"Ensure ImageNetV2 matched-frequency files are present, downloading if necessary.\"\"\"\n",
        "    os.makedirs(root, exist_ok=True)\n",
        "    if any(os.scandir(root)):\n",
        "        print(\"ImageNetV2 directory not empty; assuming data is present.\")\n",
        "        return root\n",
        "\n",
        "    if not HF_AVAILABLE:\n",
        "        raise RuntimeError(\"huggingface_hub not installed; install it or manually extract the tar.\")\n",
        "\n",
        "    print(\"Downloading ImageNetV2 matched-frequency from Hugging Face...\")\n",
        "    tar_path = hf_hub_download(\n",
        "        repo_id=\"vaishaal/ImageNetV2\",\n",
        "        filename=\"imagenetv2-matched-frequency.tar.gz\"\n",
        "    )\n",
        "\n",
        "    import tarfile\n",
        "    with tarfile.open(tar_path, \"r:gz\") as tar:\n",
        "        tar.extractall(path=root)\n",
        "\n",
        "    print(\"Extracted ImageNetV2 under\", root)\n",
        "    return root\n",
        "\n",
        "\n",
        "def load_imagenetv2(root: str):\n",
        "    \"\"\"Load ImageNetV2 matched-frequency split via ImageFolder.\"\"\"\n",
        "    ensure_imagenetv2_matched_frequency(root)\n",
        "    entries = [e for e in os.scandir(root) if e.is_dir()]\n",
        "    if len(entries) == 1:\n",
        "        data_root = entries[0].path\n",
        "    else:\n",
        "        data_root = root\n",
        "\n",
        "    ds = datasets.ImageFolder(root=data_root, transform=imagenet_transform)\n",
        "    print(\"Loaded ImageNetV2 matched-frequency with\", len(ds), \"images.\")\n",
        "    return ds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded ImageNet-Val with 50000 images.\n",
            "ImageNetV2 directory not empty; assuming data is present.\n",
            "Loaded ImageNetV2 matched-frequency with 10000 images.\n"
          ]
        }
      ],
      "source": [
        "imagenet_val = load_imagenet_val(IMAGENET_ROOT)\n",
        "imagenetv2 = load_imagenetv2(IMAGENETV2_ROOT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_for_calibration_and_eval(\n",
        "    dataset,\n",
        "    n_cal: int,\n",
        "    n_eval: int,\n",
        "    seed: int = 0\n",
        ") -> Tuple[Subset, Subset]:\n",
        "    indices = np.arange(len(dataset))\n",
        "    rng = np.random.default_rng(seed)\n",
        "    rng.shuffle(indices)\n",
        "\n",
        "    n_total = min(len(indices), n_cal + n_eval)\n",
        "    indices = indices[:n_total]\n",
        "\n",
        "    cal_indices = indices[: min(n_cal, len(indices))]\n",
        "    eval_indices = indices[min(n_cal, len(indices)): min(n_cal + n_eval, len(indices))]\n",
        "\n",
        "    cal_set = Subset(dataset, cal_indices)\n",
        "    eval_set = Subset(dataset, eval_indices)\n",
        "    return cal_set, eval_set\n",
        "\n",
        "\n",
        "def make_loader(dataset, batch_size: int = BATCH_SIZE, shuffle: bool = False):\n",
        "    return DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_pretrained_model(model_name: str = \"resnet152\") -> nn.Module:\n",
        "    \"\"\"Load a pretrained ImageNet classifier.\"\"\"\n",
        "    if model_name == \"resnet152\":\n",
        "        model = models.resnet152(weights=models.ResNet152_Weights.IMAGENET1K_V2)\n",
        "    elif model_name == \"resnet50\":\n",
        "        model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model_name: {model_name}\")\n",
        "    model.eval()\n",
        "    model.to(DEVICE)\n",
        "    return model\n",
        "\n",
        "\n",
        "class TemperatureScaler(nn.Module):\n",
        "    \"\"\"Simple temperature scaling for logits.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.log_temperature = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    @property\n",
        "    def temperature(self):\n",
        "        return torch.exp(self.log_temperature)\n",
        "\n",
        "    def forward(self, logits: torch.Tensor) -> torch.Tensor:\n",
        "        return logits / self.temperature\n",
        "\n",
        "\n",
        "def fit_temperature(model: nn.Module, loader: DataLoader, max_iters: int = 100) -> TemperatureScaler:\n",
        "    \"\"\"Fit temperature scaling using NLL loss on provided loader.\"\"\"\n",
        "    model.eval()\n",
        "    scaler = TemperatureScaler().to(DEVICE)\n",
        "    nll = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.LBFGS([scaler.log_temperature], lr=0.1)\n",
        "\n",
        "    logits_list = []\n",
        "    labels_list = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(loader, desc=\"Collecting logits for temperature scaling\"):\n",
        "            images = images.to(DEVICE)\n",
        "            logits = model(images)\n",
        "            logits_list.append(logits.cpu())\n",
        "            labels_list.append(labels)\n",
        "\n",
        "    logits_all = torch.cat(logits_list, dim=0).to(DEVICE)\n",
        "    labels_all = torch.cat(labels_list, dim=0).to(DEVICE)\n",
        "\n",
        "    def eval_loss():\n",
        "        optimizer.zero_grad()\n",
        "        loss = nll(scaler(logits_all), labels_all)\n",
        "        loss.backward()\n",
        "        return loss\n",
        "\n",
        "    for _ in range(max_iters):\n",
        "        optimizer.step(eval_loss)\n",
        "\n",
        "    print(f\"Fitted temperature: {scaler.temperature.item():.4f}\")\n",
        "    scaler.eval()\n",
        "    return scaler\n",
        "\n",
        "\n",
        "def get_logits_and_labels(model: nn.Module, loader: DataLoader, temperature_scaler: TemperatureScaler = None, \n",
        "                          checkpoint_path: str = None, save_every_n_batches: int = 10):\n",
        "    \"\"\"Compute logits and labels for a dataset loader with checkpointing support.\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    # Try to load checkpoint if it exists\n",
        "    if checkpoint_path and os.path.exists(checkpoint_path):\n",
        "        print(f\"Loading checkpoint from {checkpoint_path}\")\n",
        "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
        "        logits_list = checkpoint.get('logits_list', [])\n",
        "        labels_list = checkpoint.get('labels_list', [])\n",
        "        start_batch = checkpoint.get('batch_idx', 0)\n",
        "        print(f\"Resuming from batch {start_batch}/{len(loader)}\")\n",
        "    else:\n",
        "        logits_list = []\n",
        "        labels_list = []\n",
        "        start_batch = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        # Process batches, skipping already processed ones\n",
        "        pbar = tqdm(enumerate(loader), desc=\"Getting logits\", total=len(loader), initial=start_batch)\n",
        "        for batch_idx, (images, labels) in pbar:\n",
        "            if batch_idx < start_batch:\n",
        "                continue  # Skip already processed batches\n",
        "                \n",
        "            images = images.to(DEVICE)\n",
        "            logits = model(images)\n",
        "            if temperature_scaler is not None:\n",
        "                logits = temperature_scaler(logits)\n",
        "            logits_list.append(logits.cpu())\n",
        "            labels_list.append(labels)\n",
        "            \n",
        "            # Save checkpoint periodically\n",
        "            if checkpoint_path and (batch_idx + 1) % save_every_n_batches == 0:\n",
        "                checkpoint = {\n",
        "                    'logits_list': logits_list,\n",
        "                    'labels_list': labels_list,\n",
        "                    'batch_idx': batch_idx + 1\n",
        "                }\n",
        "                torch.save(checkpoint, checkpoint_path)\n",
        "                print(f\"  Checkpoint saved at batch {batch_idx + 1}\")\n",
        "\n",
        "    logits_all = torch.cat(logits_list, dim=0)\n",
        "    labels_all = torch.cat(labels_list, dim=0)\n",
        "    \n",
        "    # Save final checkpoint\n",
        "    if checkpoint_path:\n",
        "        checkpoint = {\n",
        "            'logits_list': logits_list,\n",
        "            'labels_list': labels_list,\n",
        "            'batch_idx': len(loader)\n",
        "        }\n",
        "        torch.save(checkpoint, checkpoint_path)\n",
        "        print(f\"Final checkpoint saved\")\n",
        "    \n",
        "    return logits_all, labels_all\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def softmax_logits_to_probs(logits: torch.Tensor) -> torch.Tensor:\n",
        "    return torch.nn.functional.softmax(logits, dim=1)\n",
        "\n",
        "\n",
        "def sorted_probs_and_indices(probs: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    sorted_probs, sorted_indices = torch.sort(probs, dim=1, descending=True)\n",
        "    return sorted_probs, sorted_indices\n",
        "\n",
        "\n",
        "def true_label_ranks(sorted_indices: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
        "    N, K = sorted_indices.shape\n",
        "    labels_expanded = labels.view(N, 1).expand(-1, K)\n",
        "    matches = (sorted_indices == labels_expanded)\n",
        "    ranks = matches.float().argmax(dim=1)\n",
        "    return ranks\n",
        "\n",
        "\n",
        "def cumulative_probs(sorted_probs: torch.Tensor) -> torch.Tensor:\n",
        "    return torch.cumsum(sorted_probs, dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def naive_set_sizes(sorted_probs: torch.Tensor, alphas: List[float]) -> Dict[float, torch.Tensor]:\n",
        "    cumsums = cumulative_probs(sorted_probs)\n",
        "    N, K = sorted_probs.shape\n",
        "    sizes_by_alpha = {}\n",
        "\n",
        "    for alpha in alphas:\n",
        "        threshold = 1.0 - alpha\n",
        "        mask = (cumsums >= threshold)\n",
        "        first_true = mask.float().argmax(dim=1)\n",
        "        no_true = ~mask.any(dim=1)\n",
        "        first_true[no_true] = K - 1\n",
        "        sizes_by_alpha[alpha] = first_true + 1\n",
        "    return sizes_by_alpha\n",
        "\n",
        "\n",
        "def naive_prediction_sets(sorted_indices: torch.Tensor, set_sizes: torch.Tensor) -> List[torch.Tensor]:\n",
        "    N, K = sorted_indices.shape\n",
        "    sets = []\n",
        "    for i in range(N):\n",
        "        L = int(set_sizes[i].item())\n",
        "        sets.append(sorted_indices[i, :L])\n",
        "    return sets\n",
        "\n",
        "\n",
        "def raps_calibrate(sorted_probs: torch.Tensor,\n",
        "                   sorted_indices: torch.Tensor,\n",
        "                   labels: torch.Tensor,\n",
        "                   alpha: float,\n",
        "                   lambda_: float,\n",
        "                   k_reg: int,\n",
        "                   randomized: bool = True,\n",
        "                   rng: np.random.Generator = None) -> float:\n",
        "    if rng is None:\n",
        "        rng = np.random.default_rng(0)\n",
        "\n",
        "    N, K = sorted_probs.shape\n",
        "    ranks = true_label_ranks(sorted_indices, labels)\n",
        "    cumsums = cumulative_probs(sorted_probs)\n",
        "\n",
        "    S_true = cumsums[torch.arange(N), ranks]\n",
        "    ranks_1based = ranks + 1\n",
        "    penalty = lambda_ * torch.clamp(ranks_1based - k_reg, min=0).float()\n",
        "\n",
        "    E = S_true + penalty\n",
        "\n",
        "    if randomized:\n",
        "        U = torch.from_numpy(rng.uniform(size=N)).float()\n",
        "        true_probs = sorted_probs[torch.arange(N), ranks]\n",
        "        E = E - U * true_probs\n",
        "\n",
        "    E_np = E.numpy()\n",
        "    n = len(E_np)\n",
        "    q_index = int(np.ceil((1.0 - alpha) * (n + 1))) - 1\n",
        "    q_index = np.clip(q_index, 0, n - 1)\n",
        "    tau_hat = float(np.partition(E_np, q_index)[q_index])\n",
        "    return tau_hat\n",
        "\n",
        "\n",
        "def raps_set_sizes(sorted_probs: torch.Tensor,\n",
        "                   alpha: float,\n",
        "                   lambda_: float,\n",
        "                   k_reg: int,\n",
        "                   tau_hat: float) -> torch.Tensor:\n",
        "    N, K = sorted_probs.shape\n",
        "    cumsums = cumulative_probs(sorted_probs)\n",
        "\n",
        "    ranks_1based = torch.arange(1, K + 1)\n",
        "    penalties = lambda_ * torch.clamp(ranks_1based - k_reg, min=0).float()\n",
        "    penalties = penalties.view(1, K).expand(N, -1)\n",
        "\n",
        "    E_all = cumsums + penalties\n",
        "\n",
        "    mask = (E_all > tau_hat)\n",
        "    all_false = ~mask.any(dim=1)\n",
        "    first_exceed = mask.float().argmax(dim=1)\n",
        "    first_exceed[all_false] = K\n",
        "\n",
        "    sizes = first_exceed\n",
        "    sizes[all_false] = K\n",
        "    sizes = torch.clamp(sizes, min=1)\n",
        "    return sizes\n",
        "\n",
        "\n",
        "def aps_calibrate_and_sizes(sorted_probs_cal, sorted_indices_cal, labels_cal,\n",
        "                            sorted_probs_eval, alpha, k_reg=0):\n",
        "    tau_hat = raps_calibrate(\n",
        "        sorted_probs_cal, sorted_indices_cal, labels_cal,\n",
        "        alpha=alpha, lambda_=0.0, k_reg=k_reg\n",
        "    )\n",
        "    sizes = raps_set_sizes(\n",
        "        sorted_probs_eval, alpha=alpha,\n",
        "        lambda_=0.0, k_reg=k_reg, tau_hat=tau_hat\n",
        "    )\n",
        "    return tau_hat, sizes\n",
        "\n",
        "\n",
        "def raps_calibrate_and_sizes(sorted_probs_cal, sorted_indices_cal, labels_cal,\n",
        "                             sorted_probs_eval, alpha,\n",
        "                             lambda_=DEFAULT_LAMBDA, k_reg=DEFAULT_KREG):\n",
        "    tau_hat = raps_calibrate(\n",
        "        sorted_probs_cal, sorted_indices_cal, labels_cal,\n",
        "        alpha=alpha, lambda_=lambda_, k_reg=k_reg\n",
        "    )\n",
        "    sizes = raps_set_sizes(\n",
        "        sorted_probs_eval, alpha=alpha,\n",
        "        lambda_=lambda_, k_reg=k_reg, tau_hat=tau_hat\n",
        "    )\n",
        "    return tau_hat, sizes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_scores(scores: dict, filepath: str):\n",
        "    \"\"\"Save computed scores to disk.\"\"\"\n",
        "    os.makedirs(os.path.dirname(filepath) if os.path.dirname(filepath) else '.', exist_ok=True)\n",
        "    torch.save(scores, filepath)\n",
        "    print(f\"Saved scores to {filepath}\")\n",
        "\n",
        "\n",
        "def load_scores(filepath: str) -> dict:\n",
        "    \"\"\"Load computed scores from disk.\"\"\"\n",
        "    if os.path.exists(filepath):\n",
        "        scores = torch.load(filepath, map_location='cpu')\n",
        "        print(f\"Loaded scores from {filepath}\")\n",
        "        return scores\n",
        "    return None\n",
        "\n",
        "\n",
        "def load_scores_by_name(dataset_name: str, n_cal: int, n_eval: int, seed: int = 0) -> dict:\n",
        "    \"\"\"\n",
        "    Helper function to load scores by dataset name and parameters.\n",
        "    Useful for recovering from kernel crashes.\n",
        "    \n",
        "    Args:\n",
        "        dataset_name: 'imagenet' or 'imagenetv2'\n",
        "        n_cal: Number of calibration samples\n",
        "        n_eval: Number of evaluation samples\n",
        "        seed: Random seed used\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary of scores or None if not found\n",
        "    \"\"\"\n",
        "    cache_file = os.path.join(RESULTS_DIR, f\"scores_{dataset_name}_cal{n_cal}_eval{n_eval}_seed{seed}.pt\")\n",
        "    return load_scores(cache_file)\n",
        "\n",
        "\n",
        "def compute_scores_for_dataset(model: nn.Module,\n",
        "                               dataset,\n",
        "                               n_cal: int,\n",
        "                               n_eval: int,\n",
        "                               seed: int = 0,\n",
        "                               temperature_scaler: TemperatureScaler = None,\n",
        "                               cache_file: str = None,\n",
        "                               use_cache: bool = True):\n",
        "    \"\"\"\n",
        "    Compute scores for a dataset with optional caching.\n",
        "    \n",
        "    Args:\n",
        "        cache_file: Path to save/load cached scores. If None, uses RESULTS_DIR.\n",
        "        use_cache: If True, load from cache if available and save results.\n",
        "    \"\"\"\n",
        "    # Generate cache filename if not provided\n",
        "    if cache_file is None:\n",
        "        # Try to identify dataset type\n",
        "        dataset_type = type(dataset).__name__\n",
        "        dataset_root = str(getattr(dataset, 'root', ''))\n",
        "        \n",
        "        if 'ImageNet' in dataset_type or 'ilsvrc' in dataset_root.lower():\n",
        "            dataset_name = 'imagenet'\n",
        "        elif 'ImageFolder' in dataset_type and 'imagenetv2' in dataset_root.lower():\n",
        "            dataset_name = 'imagenetv2'\n",
        "        else:\n",
        "            # Fallback: use a hash of the root path to create a safe filename\n",
        "            import hashlib\n",
        "            root_hash = hashlib.md5(dataset_root.encode()).hexdigest()[:8]\n",
        "            dataset_name = f'dataset_{root_hash}'\n",
        "        \n",
        "        cache_file = os.path.join(RESULTS_DIR, f\"scores_{dataset_name}_cal{n_cal}_eval{n_eval}_seed{seed}.pt\")\n",
        "    \n",
        "    # Try to load from cache\n",
        "    if use_cache:\n",
        "        cached_scores = load_scores(cache_file)\n",
        "        if cached_scores is not None:\n",
        "            return cached_scores\n",
        "    \n",
        "    # Compute scores\n",
        "    cal_set, eval_set = split_for_calibration_and_eval(dataset, n_cal, n_eval, seed=seed)\n",
        "    cal_loader = make_loader(cal_set, shuffle=False)\n",
        "    eval_loader = make_loader(eval_set, shuffle=False)\n",
        "\n",
        "    # Use checkpointing for logits computation\n",
        "    cal_checkpoint = cache_file.replace('.pt', '_cal_checkpoint.pt') if cache_file else None\n",
        "    eval_checkpoint = cache_file.replace('.pt', '_eval_checkpoint.pt') if cache_file else None\n",
        "    \n",
        "    logits_cal, labels_cal = get_logits_and_labels(\n",
        "        model, cal_loader, temperature_scaler, \n",
        "        checkpoint_path=cal_checkpoint, save_every_n_batches=10\n",
        "    )\n",
        "    logits_eval, labels_eval = get_logits_and_labels(\n",
        "        model, eval_loader, temperature_scaler,\n",
        "        checkpoint_path=eval_checkpoint, save_every_n_batches=10\n",
        "    )\n",
        "\n",
        "    probs_cal = torch.softmax(logits_cal, dim=1)\n",
        "    probs_eval = torch.softmax(logits_eval, dim=1)\n",
        "\n",
        "    s_cal, I_cal = sorted_probs_and_indices(probs_cal)\n",
        "    s_eval, I_eval = sorted_probs_and_indices(probs_eval)\n",
        "\n",
        "    scores = {\n",
        "        \"cal\": {\"logits\": logits_cal, \"labels\": labels_cal, \"probs\": probs_cal, \"sorted_probs\": s_cal, \"sorted_indices\": I_cal},\n",
        "        \"eval\": {\"logits\": logits_eval, \"labels\": labels_eval, \"probs\": probs_eval, \"sorted_probs\": s_eval, \"sorted_indices\": I_eval},\n",
        "    }\n",
        "    \n",
        "    # Save to cache\n",
        "    if use_cache:\n",
        "        save_scores(scores, cache_file)\n",
        "        # Clean up checkpoint files after successful completion\n",
        "        if cal_checkpoint and os.path.exists(cal_checkpoint):\n",
        "            os.remove(cal_checkpoint)\n",
        "        if eval_checkpoint and os.path.exists(eval_checkpoint):\n",
        "            os.remove(eval_checkpoint)\n",
        "    \n",
        "    # Memory cleanup - delete intermediate tensors to free memory\n",
        "    del logits_cal, logits_eval, probs_cal, probs_eval\n",
        "    import gc\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    return scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def coverage_from_set_sizes_and_labels(\n",
        "    sorted_indices: torch.Tensor,\n",
        "    set_sizes: torch.Tensor,\n",
        "    labels: torch.Tensor\n",
        ") -> float:\n",
        "    N, K = sorted_indices.shape\n",
        "    correct = 0\n",
        "    for i in range(N):\n",
        "        L = int(set_sizes[i].item())\n",
        "        preds = sorted_indices[i, :L]\n",
        "        if int(labels[i].item()) in preds.tolist():\n",
        "            correct += 1\n",
        "    return correct / float(N)\n",
        "\n",
        "\n",
        "def average_set_size(set_sizes: torch.Tensor) -> float:\n",
        "    return float(set_sizes.float().mean().item())\n",
        "\n",
        "\n",
        "def topk_accuracies_from_probs(probs: torch.Tensor,\n",
        "                               labels: torch.Tensor,\n",
        "                               ks=(1, 5)) -> Dict[int, float]:\n",
        "    _, topk_indices = probs.topk(max(ks), dim=1)\n",
        "    results = {}\n",
        "    for k in ks:\n",
        "        correct = (topk_indices[:, :k] == labels.view(-1, 1)).any(dim=1).float().mean().item()\n",
        "        results[k] = correct\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 1 â€“ Coverage vs set size on ImageNet-Val\n",
        "\n",
        "Run Naive, APS, and RAPS on ImageNet validation set (if available)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded scores from ./results\\scores_imagenet_cal20000_eval20000_seed0.pt\n",
            "âœ“ Scores computed and saved successfully\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'numpy' has no attribute 'matrix'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\ducta\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'top1'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\ducta\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4485\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[1;34m(self, key, value, refs)\u001b[0m\n\u001b[0;32m   4484\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 4485\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4486\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m   4487\u001b[0m     \u001b[38;5;66;03m# This item wasn't present, just insert at end\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\ducta\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'top1'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[27], line 63\u001b[0m\n\u001b[0;32m     61\u001b[0m df_exp1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(rows)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Assign top-k accuracies (same value for all rows)\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m df_exp1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [topk[\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(df_exp1)\n\u001b[0;32m     64\u001b[0m df_exp1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop5\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [topk[\u001b[38;5;241m5\u001b[39m]] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(df_exp1)\n\u001b[0;32m     65\u001b[0m display(df_exp1)\n",
            "File \u001b[1;32mc:\\Users\\ducta\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4311\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   4309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4310\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 4311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item(key, value)\n",
            "File \u001b[1;32mc:\\Users\\ducta\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4538\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4535\u001b[0m             value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(value, (\u001b[38;5;28mlen\u001b[39m(existing_piece\u001b[38;5;241m.\u001b[39mcolumns), \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m   4536\u001b[0m             refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 4538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item_mgr(key, value, refs)\n",
            "File \u001b[1;32mc:\\Users\\ducta\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4488\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[1;34m(self, key, value, refs)\u001b[0m\n\u001b[0;32m   4485\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4486\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m   4487\u001b[0m     \u001b[38;5;66;03m# This item wasn't present, just insert at end\u001b[39;00m\n\u001b[1;32m-> 4488\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis), key, value, refs)\n\u001b[0;32m   4489\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4490\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iset_item_mgr(loc, value, refs\u001b[38;5;241m=\u001b[39mrefs)\n",
            "File \u001b[1;32mc:\\Users\\ducta\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1385\u001b[0m, in \u001b[0;36mBlockManager.insert\u001b[1;34m(self, loc, item, value, refs)\u001b[0m\n\u001b[0;32m   1383\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_update_mgr_locs(loc)\n\u001b[1;32m-> 1385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_update_blklocs_and_blknos(loc)\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m new_axis\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (block,)\n",
            "File \u001b[1;32mc:\\Users\\ducta\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1421\u001b[0m, in \u001b[0;36mBlockManager._insert_update_blklocs_and_blknos\u001b[1;34m(self, loc)\u001b[0m\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;66;03m# Accessing public blklocs ensures the public versions are initialized\u001b[39;00m\n\u001b[0;32m   1419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loc \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblklocs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m   1420\u001b[0m     \u001b[38;5;66;03m# np.append is a lot faster, let's use it if we can.\u001b[39;00m\n\u001b[1;32m-> 1421\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1422\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blknos \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blknos, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks))\n\u001b[0;32m   1423\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m loc \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;66;03m# np.append is a lot faster, let's use it if we can.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\ducta\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:5616\u001b[0m, in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   5614\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   5615\u001b[0m         arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m-> 5616\u001b[0m     values \u001b[38;5;241m=\u001b[39m ravel(values)\n\u001b[0;32m   5617\u001b[0m     axis \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   5618\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concatenate((arr, values), axis\u001b[38;5;241m=\u001b[39maxis)\n",
            "File \u001b[1;32mc:\\Users\\ducta\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:1871\u001b[0m, in \u001b[0;36mravel\u001b[1;34m(a, order)\u001b[0m\n\u001b[0;32m   1768\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_ravel_dispatcher)\n\u001b[0;32m   1769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mravel\u001b[39m(a, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1770\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a contiguous flattened array.\u001b[39;00m\n\u001b[0;32m   1771\u001b[0m \n\u001b[0;32m   1772\u001b[0m \u001b[38;5;124;03m    A 1-D array, containing the elements of the input, is returned.  A copy is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1869\u001b[0m \n\u001b[0;32m   1870\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, np\u001b[38;5;241m.\u001b[39mmatrix):\n\u001b[0;32m   1872\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m asarray(a)\u001b[38;5;241m.\u001b[39mravel(order\u001b[38;5;241m=\u001b[39morder)\n\u001b[0;32m   1873\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'matrix'"
          ]
        }
      ],
      "source": [
        "if imagenet_val is None:\n",
        "    print(\"ImageNet not available; skipping Experiment 1.\")\n",
        "else:\n",
        "    # Step 1: Compute scores (this may take a while, but is checkpointed)\n",
        "    model = load_pretrained_model(\"resnet152\")\n",
        "    \n",
        "    try:\n",
        "        scores_imagenet = compute_scores_for_dataset(\n",
        "            model,\n",
        "            dataset=imagenet_val,\n",
        "            n_cal=IMAGENET_N_CAL,\n",
        "            n_eval=IMAGENET_N_EVAL,\n",
        "            seed=0,\n",
        "            temperature_scaler=None,\n",
        "        )\n",
        "        print(\"âœ“ Scores computed and saved successfully\")\n",
        "    finally:\n",
        "        # Free model memory immediately after computation\n",
        "        del model\n",
        "        import gc\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "    \n",
        "    # Step 2: Load scores and run analysis (separate to avoid memory issues)\n",
        "    # If scores were just computed, they're already in memory\n",
        "    # If kernel crashed during analysis, reload from cache\n",
        "    try:\n",
        "        # Check if scores exist in memory\n",
        "        _ = scores_imagenet\n",
        "    except NameError:\n",
        "        print(\"Scores not in memory, loading from cache...\")\n",
        "        scores_imagenet = load_scores_by_name('imagenet', IMAGENET_N_CAL, IMAGENET_N_EVAL, seed=0)\n",
        "        if scores_imagenet is None:\n",
        "            raise RuntimeError(\"Scores not found in cache. Please run the computation step first.\")\n",
        "    \n",
        "    s_cal = scores_imagenet[\"cal\"][\"sorted_probs\"]\n",
        "    I_cal = scores_imagenet[\"cal\"][\"sorted_indices\"]\n",
        "    labels_cal = scores_imagenet[\"cal\"][\"labels\"]\n",
        "\n",
        "    s_eval = scores_imagenet[\"eval\"][\"sorted_probs\"]\n",
        "    I_eval = scores_imagenet[\"eval\"][\"sorted_indices\"]\n",
        "    labels_eval = scores_imagenet[\"eval\"][\"labels\"]\n",
        "\n",
        "    topk = topk_accuracies_from_probs(scores_imagenet[\"eval\"][\"probs\"], labels_eval)\n",
        "\n",
        "    rows = []\n",
        "    for alpha in ALPHAS:\n",
        "        sizes_naive = naive_set_sizes(s_eval, [alpha])[alpha]\n",
        "        cov_naive = coverage_from_set_sizes_and_labels(I_eval, sizes_naive, labels_eval)\n",
        "        rows.append({\"alpha\": alpha, \"method\": \"Naive\", \"coverage\": cov_naive, \"avg_set_size\": average_set_size(sizes_naive)})\n",
        "\n",
        "        tau_aps, sizes_aps = aps_calibrate_and_sizes(s_cal, I_cal, labels_cal, s_eval, alpha, k_reg=0)\n",
        "        cov_aps = coverage_from_set_sizes_and_labels(I_eval, sizes_aps, labels_eval)\n",
        "        rows.append({\"alpha\": alpha, \"method\": \"APS\", \"coverage\": cov_aps, \"avg_set_size\": average_set_size(sizes_aps)})\n",
        "\n",
        "        tau_raps, sizes_raps = raps_calibrate_and_sizes(s_cal, I_cal, labels_cal, s_eval, alpha, lambda_=DEFAULT_LAMBDA, k_reg=DEFAULT_KREG)\n",
        "        cov_raps = coverage_from_set_sizes_and_labels(I_eval, sizes_raps, labels_eval)\n",
        "        rows.append({\"alpha\": alpha, \"method\": \"RAPS\", \"coverage\": cov_raps, \"avg_set_size\": average_set_size(sizes_raps)})\n",
        "\n",
        "    df_exp1 = pd.DataFrame(rows)\n",
        "    # Assign top-k accuracies (same value for all rows)\n",
        "    df_exp1[\"top1\"] = [topk[1]] * len(df_exp1)\n",
        "    df_exp1[\"top5\"] = [topk[5]] * len(df_exp1)\n",
        "    display(df_exp1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 2 â€“ Coverage vs set size on ImageNetV2\n",
        "\n",
        "Repeat on the ImageNetV2 matched-frequency split to assess robustness under distribution shift."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded scores from ./results\\scores_imagenetv2_cal5000_eval5000_seed1.pt\n",
            "âœ“ Scores computed and saved successfully\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alpha</th>\n",
              "      <th>method</th>\n",
              "      <th>coverage</th>\n",
              "      <th>avg_set_size</th>\n",
              "      <th>top1</th>\n",
              "      <th>top5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.05</td>\n",
              "      <td>Naive</td>\n",
              "      <td>0.6098</td>\n",
              "      <td>623.763611</td>\n",
              "      <td>0.0096</td>\n",
              "      <td>0.0212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.05</td>\n",
              "      <td>APS</td>\n",
              "      <td>0.9460</td>\n",
              "      <td>964.497986</td>\n",
              "      <td>0.0096</td>\n",
              "      <td>0.0212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.05</td>\n",
              "      <td>RAPS</td>\n",
              "      <td>0.9506</td>\n",
              "      <td>966.548218</td>\n",
              "      <td>0.0096</td>\n",
              "      <td>0.0212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.10</td>\n",
              "      <td>Naive</td>\n",
              "      <td>0.3884</td>\n",
              "      <td>364.788605</td>\n",
              "      <td>0.0096</td>\n",
              "      <td>0.0212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.10</td>\n",
              "      <td>APS</td>\n",
              "      <td>0.8932</td>\n",
              "      <td>923.677795</td>\n",
              "      <td>0.0096</td>\n",
              "      <td>0.0212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.10</td>\n",
              "      <td>RAPS</td>\n",
              "      <td>0.8914</td>\n",
              "      <td>922.528381</td>\n",
              "      <td>0.0096</td>\n",
              "      <td>0.0212</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   alpha method  coverage  avg_set_size    top1    top5\n",
              "0   0.05  Naive    0.6098    623.763611  0.0096  0.0212\n",
              "1   0.05    APS    0.9460    964.497986  0.0096  0.0212\n",
              "2   0.05   RAPS    0.9506    966.548218  0.0096  0.0212\n",
              "3   0.10  Naive    0.3884    364.788605  0.0096  0.0212\n",
              "4   0.10    APS    0.8932    923.677795  0.0096  0.0212\n",
              "5   0.10   RAPS    0.8914    922.528381  0.0096  0.0212"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if imagenetv2 is None:\n",
        "    print(\"ImageNetV2 not available; skipping Experiment 2.\")\n",
        "else:\n",
        "    # Step 1: Compute scores (this may take a while, but is checkpointed)\n",
        "    model = load_pretrained_model(\"resnet152\")\n",
        "    \n",
        "    try:\n",
        "        scores_imagenetv2 = compute_scores_for_dataset(\n",
        "            model,\n",
        "            dataset=imagenetv2,\n",
        "            n_cal=IMAGENETV2_N_CAL,\n",
        "            n_eval=IMAGENETV2_N_EVAL,\n",
        "            seed=1,\n",
        "            temperature_scaler=None,\n",
        "        )\n",
        "        print(\"âœ“ Scores computed and saved successfully\")\n",
        "    finally:\n",
        "        # Free model memory immediately after computation\n",
        "        del model\n",
        "        import gc\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "    \n",
        "    # Step 2: Load scores and run analysis (separate to avoid memory issues)\n",
        "    # If scores were just computed, they're already in memory\n",
        "    # If kernel crashed during analysis, reload from cache\n",
        "    try:\n",
        "        # Check if scores exist in memory\n",
        "        _ = scores_imagenetv2\n",
        "    except NameError:\n",
        "        print(\"Scores not in memory, loading from cache...\")\n",
        "        scores_imagenetv2 = load_scores_by_name('imagenetv2', IMAGENETV2_N_CAL, IMAGENETV2_N_EVAL, seed=1)\n",
        "        if scores_imagenetv2 is None:\n",
        "            raise RuntimeError(\"Scores not found in cache. Please run the computation step first.\")\n",
        "    \n",
        "    s_cal = scores_imagenetv2[\"cal\"][\"sorted_probs\"]\n",
        "    I_cal = scores_imagenetv2[\"cal\"][\"sorted_indices\"]\n",
        "    labels_cal = scores_imagenetv2[\"cal\"][\"labels\"]\n",
        "\n",
        "    s_eval = scores_imagenetv2[\"eval\"][\"sorted_probs\"]\n",
        "    I_eval = scores_imagenetv2[\"eval\"][\"sorted_indices\"]\n",
        "    labels_eval = scores_imagenetv2[\"eval\"][\"labels\"]\n",
        "\n",
        "    topk = topk_accuracies_from_probs(scores_imagenetv2[\"eval\"][\"probs\"], labels_eval)\n",
        "\n",
        "    rows = []\n",
        "    for alpha in ALPHAS:\n",
        "        sizes_naive = naive_set_sizes(s_eval, [alpha])[alpha]\n",
        "        cov_naive = coverage_from_set_sizes_and_labels(I_eval, sizes_naive, labels_eval)\n",
        "        rows.append({\"alpha\": alpha, \"method\": \"Naive\", \"coverage\": cov_naive, \"avg_set_size\": average_set_size(sizes_naive)})\n",
        "\n",
        "        tau_aps, sizes_aps = aps_calibrate_and_sizes(s_cal, I_cal, labels_cal, s_eval, alpha, k_reg=0)\n",
        "        cov_aps = coverage_from_set_sizes_and_labels(I_eval, sizes_aps, labels_eval)\n",
        "        rows.append({\"alpha\": alpha, \"method\": \"APS\", \"coverage\": cov_aps, \"avg_set_size\": average_set_size(sizes_aps)})\n",
        "\n",
        "        tau_raps, sizes_raps = raps_calibrate_and_sizes(s_cal, I_cal, labels_cal, s_eval, alpha, lambda_=DEFAULT_LAMBDA, k_reg=DEFAULT_KREG)\n",
        "        cov_raps = coverage_from_set_sizes_and_labels(I_eval, sizes_raps, labels_eval)\n",
        "        rows.append({\"alpha\": alpha, \"method\": \"RAPS\", \"coverage\": cov_raps, \"avg_set_size\": average_set_size(sizes_raps)})\n",
        "\n",
        "    df_exp2 = pd.DataFrame(rows)\n",
        "    # Assign top-k accuracies (same value for all rows)\n",
        "    df_exp2[\"top1\"] = [topk[1]] * len(df_exp2)\n",
        "    df_exp2[\"top5\"] = [topk[5]] * len(df_exp2)\n",
        "    display(df_exp2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 3 â€“ Histograms of set sizes for different $\\lambda$\n",
        "\n",
        "Visualize how RAPS set sizes vary with the regularization parameter $\\lambda$ for a fixed $\u0007lpha$ (default 0.1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "alpha_hist = 0.1\n",
        "\n",
        "def plot_histograms_for_dataset(s_cal, I_cal, labels_cal, s_eval, I_eval, labels_eval, dataset_name: str):\n",
        "    import gc\n",
        "    \n",
        "    sizes_naive = naive_set_sizes(s_eval, [alpha_hist])[alpha_hist]\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.hist(sizes_naive.numpy(), bins=range(1, 50), alpha=0.7, label=\"Naive\")\n",
        "    plt.title(f\"Experiment 3 â€“ Naive set sizes (alpha={alpha_hist}, {dataset_name})\")\n",
        "    plt.xlabel(\"Set size\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    del sizes_naive\n",
        "    gc.collect()\n",
        "\n",
        "    tau_aps, sizes_aps = aps_calibrate_and_sizes(s_cal, I_cal, labels_cal, s_eval, alpha_hist, k_reg=0)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.hist(sizes_aps.numpy(), bins=range(1, 50), alpha=0.7, label=\"APS\")\n",
        "    plt.title(f\"Experiment 3 â€“ APS set sizes (alpha={alpha_hist}, {dataset_name})\")\n",
        "    plt.xlabel(\"Set size\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    del tau_aps, sizes_aps\n",
        "    gc.collect()\n",
        "\n",
        "    for lambda_ in RAPS_LAMBDAS_FOR_EXP3:\n",
        "        print(f\"Computing RAPS for lambda={lambda_}...\")\n",
        "        tau_raps, sizes_raps = raps_calibrate_and_sizes(\n",
        "            s_cal, I_cal, labels_cal, s_eval, alpha_hist, lambda_=lambda_, k_reg=DEFAULT_KREG\n",
        "        )\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        plt.hist(sizes_raps.numpy(), bins=range(1, 50), alpha=0.7, label=f\"RAPS lambda={lambda_}\")\n",
        "        plt.title(f\"Experiment 3 â€“ RAPS set sizes (alpha={alpha_hist}, lambda={lambda_}, {dataset_name})\")\n",
        "        plt.xlabel(\"Set size\")\n",
        "        plt.ylabel(\"Count\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        # Clean up after each plot\n",
        "        del tau_raps, sizes_raps\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "if imagenet_val is not None:\n",
        "    # Try to get scores from memory, otherwise load from cache\n",
        "    try:\n",
        "        scores = scores_imagenet\n",
        "    except NameError:\n",
        "        print(\"Loading ImageNet scores from cache...\")\n",
        "        scores = load_scores_by_name('imagenet', IMAGENET_N_CAL, IMAGENET_N_EVAL, seed=0)\n",
        "        if scores is None:\n",
        "            print(\"Scores not found. Computing scores (this may take a while)...\")\n",
        "            model = load_pretrained_model(\"resnet152\")\n",
        "            try:\n",
        "                scores = compute_scores_for_dataset(model, imagenet_val, IMAGENET_N_CAL, IMAGENET_N_EVAL)\n",
        "            finally:\n",
        "                del model\n",
        "                import gc\n",
        "                gc.collect()\n",
        "                if torch.cuda.is_available():\n",
        "                    torch.cuda.empty_cache()\n",
        "    \n",
        "    plot_histograms_for_dataset(\n",
        "        scores[\"cal\"][\"sorted_probs\"], scores[\"cal\"][\"sorted_indices\"], scores[\"cal\"][\"labels\"],\n",
        "        scores[\"eval\"][\"sorted_probs\"], scores[\"eval\"][\"sorted_indices\"], scores[\"eval\"][\"labels\"],\n",
        "        dataset_name=\"ImageNet-Val\"\n",
        "    )\n",
        "elif imagenetv2 is not None:\n",
        "    # Try to get scores from memory, otherwise load from cache\n",
        "    try:\n",
        "        scores = scores_imagenetv2\n",
        "    except NameError:\n",
        "        print(\"Loading ImageNetV2 scores from cache...\")\n",
        "        scores = load_scores_by_name('imagenetv2', IMAGENETV2_N_CAL, IMAGENETV2_N_EVAL, seed=1)\n",
        "        if scores is None:\n",
        "            print(\"Scores not found. Computing scores (this may take a while)...\")\n",
        "            model = load_pretrained_model(\"resnet152\")\n",
        "            try:\n",
        "                scores = compute_scores_for_dataset(model, imagenetv2, IMAGENETV2_N_CAL, IMAGENETV2_N_EVAL)\n",
        "            finally:\n",
        "                del model\n",
        "                import gc\n",
        "                gc.collect()\n",
        "                if torch.cuda.is_available():\n",
        "                    torch.cuda.empty_cache()\n",
        "    \n",
        "    plot_histograms_for_dataset(\n",
        "        scores[\"cal\"][\"sorted_probs\"], scores[\"cal\"][\"sorted_indices\"], scores[\"cal\"][\"labels\"],\n",
        "        scores[\"eval\"][\"sorted_probs\"], scores[\"eval\"][\"sorted_indices\"], scores[\"eval\"][\"labels\"],\n",
        "        dataset_name=\"ImageNetV2\"\n",
        "    )\n",
        "else:\n",
        "    print(\"No datasets available for Experiment 3.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 4 â€“ Adaptiveness of RAPS vs difficulty\n",
        "\n",
        "Analyze how RAPS set sizes change across difficulty bins defined by true-class probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "alpha_adapt = 0.1\n",
        "lambda_adapt = DEFAULT_LAMBDA\n",
        "\n",
        "\n",
        "def analyze_adaptiveness(s_cal, I_cal, labels_cal, s_eval, I_eval, labels_eval, dataset_name: str):\n",
        "    tau_raps, sizes_raps = raps_calibrate_and_sizes(\n",
        "        s_cal, I_cal, labels_cal, s_eval, alpha_adapt, lambda_=lambda_adapt, k_reg=DEFAULT_KREG\n",
        "    )\n",
        "\n",
        "    true_ranks = true_label_ranks(I_eval, labels_eval)\n",
        "    true_probs = s_eval[torch.arange(len(s_eval)), true_ranks]\n",
        "\n",
        "    quantiles = torch.quantile(true_probs, torch.tensor([0.25, 0.5, 0.75]))\n",
        "    bins = [true_probs < quantiles[0],\n",
        "            (true_probs >= quantiles[0]) & (true_probs < quantiles[1]),\n",
        "            (true_probs >= quantiles[1]) & (true_probs < quantiles[2]),\n",
        "            true_probs >= quantiles[2]]\n",
        "\n",
        "    avg_sizes = []\n",
        "    coverages = []\n",
        "    for i, mask in enumerate(bins):\n",
        "        idx = mask.nonzero(as_tuple=False).squeeze(1)\n",
        "        bin_sizes = sizes_raps[idx]\n",
        "        bin_labels = labels_eval[idx]\n",
        "        bin_indices = I_eval[idx]\n",
        "        avg_sizes.append(average_set_size(bin_sizes))\n",
        "        coverages.append(coverage_from_set_sizes_and_labels(bin_indices, bin_sizes, bin_labels))\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.bar(range(1, 5), avg_sizes)\n",
        "    plt.xlabel(\"Difficulty bin (1=hardest, 4=easiest)\")\n",
        "    plt.ylabel(\"Average set size\")\n",
        "    plt.title(f\"Experiment 4 â€“ Average set size by difficulty ({dataset_name})\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.bar(range(1, 5), coverages)\n",
        "    plt.xlabel(\"Difficulty bin (1=hardest, 4=easiest)\")\n",
        "    plt.ylabel(\"Coverage\")\n",
        "    plt.title(f\"Experiment 4 â€“ Coverage by difficulty ({dataset_name})\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if imagenet_val is not None:\n",
        "    # Try to get scores from memory, otherwise load from cache\n",
        "    try:\n",
        "        scores = scores_imagenet\n",
        "    except NameError:\n",
        "        print(\"Loading ImageNet scores from cache...\")\n",
        "        scores = load_scores_by_name('imagenet', IMAGENET_N_CAL, IMAGENET_N_EVAL, seed=0)\n",
        "        if scores is None:\n",
        "            print(\"Scores not found. Computing scores (this may take a while)...\")\n",
        "            model = load_pretrained_model(\"resnet152\")\n",
        "            try:\n",
        "                scores = compute_scores_for_dataset(model, imagenet_val, IMAGENET_N_CAL, IMAGENET_N_EVAL)\n",
        "            finally:\n",
        "                del model\n",
        "                import gc\n",
        "                gc.collect()\n",
        "                if torch.cuda.is_available():\n",
        "                    torch.cuda.empty_cache()\n",
        "    \n",
        "    analyze_adaptiveness(\n",
        "        scores[\"cal\"][\"sorted_probs\"], scores[\"cal\"][\"sorted_indices\"], scores[\"cal\"][\"labels\"],\n",
        "        scores[\"eval\"][\"sorted_probs\"], scores[\"eval\"][\"sorted_indices\"], scores[\"eval\"][\"labels\"],\n",
        "        dataset_name=\"ImageNet-Val\"\n",
        "    )\n",
        "elif imagenetv2 is not None:\n",
        "    # Try to get scores from memory, otherwise load from cache\n",
        "    try:\n",
        "        scores = scores_imagenetv2\n",
        "    except NameError:\n",
        "        print(\"Loading ImageNetV2 scores from cache...\")\n",
        "        scores = load_scores_by_name('imagenetv2', IMAGENETV2_N_CAL, IMAGENETV2_N_EVAL, seed=1)\n",
        "        if scores is None:\n",
        "            print(\"Scores not found. Computing scores (this may take a while)...\")\n",
        "            model = load_pretrained_model(\"resnet152\")\n",
        "            try:\n",
        "                scores = compute_scores_for_dataset(model, imagenetv2, IMAGENETV2_N_CAL, IMAGENETV2_N_EVAL)\n",
        "            finally:\n",
        "                del model\n",
        "                import gc\n",
        "                gc.collect()\n",
        "                if torch.cuda.is_available():\n",
        "                    torch.cuda.empty_cache()\n",
        "    \n",
        "    analyze_adaptiveness(\n",
        "        scores[\"cal\"][\"sorted_probs\"], scores[\"cal\"][\"sorted_indices\"], scores[\"cal\"][\"labels\"],\n",
        "        scores[\"eval\"][\"sorted_probs\"], scores[\"eval\"][\"sorted_indices\"], scores[\"eval\"][\"labels\"],\n",
        "        dataset_name=\"ImageNetV2\"\n",
        "    )\n",
        "else:\n",
        "    print(\"No datasets available for Experiment 4.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary & Notes for Written Report\n",
        "\n",
        "Fill in these bullets after running the experiments:\n",
        "\n",
        "- **Implementation details:** frameworks, model variants, dataset availability, any approximations.\n",
        "- **Experiment 1 (ImageNet-Val):** coverage vs average set size for Naive/APS/RAPS.\n",
        "- **Experiment 2 (ImageNetV2):** coverage vs average set size under distribution shift.\n",
        "- **Experiment 3:** qualitative effect of $\\lambda$ on set size histograms.\n",
        "- **Experiment 4:** adaptiveness of RAPS across difficulty bins.\n",
        "- **Critique & extensions:** strengths, limitations, and potential improvements.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
